{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import elasticsearch\n",
    "    from elasticsearch import Elasticsearch\n",
    "    \n",
    "    import pandas as pd\n",
    "    import json\n",
    "    from ast import literal_eval\n",
    "    from tqdm import tqdm\n",
    "    import datetime\n",
    "    import os\n",
    "    import sys\n",
    "    \n",
    "    import os\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    from elasticsearch import helpers\n",
    "    \n",
    "    from gensim.models import Word2Vec, KeyedVectors\n",
    "    \n",
    "    import nltk\n",
    "    import re\n",
    "    from nltk.corpus import stopwords\n",
    "    nltk.download('stopwords')\n",
    "    \n",
    "    import spacy\n",
    "\n",
    "    print(\"Loaded  .. . . . . . . .\")\n",
    "except Exception as E:\n",
    "    print(\"Some Modules are Missing {} \".format(E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"val_knowledgebase.csv\")\n",
    "print(\"read\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_serving.client import BertClient\n",
    "bc = BertClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country=df[\"country\"]\n",
    "country_set=set(country)\n",
    "product=df[\"product\"]\n",
    "product_set=set(product)\n",
    "print(\"countries : \"+str(country_set))\n",
    "print(\"products : \"+str(product_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load fasttext modelnlp=spacy.load('en_core_web_lg')\n",
    "data_path_fast= \"/home/srinivas/Downloads\"\n",
    "path_to_model_fasttext= os.path.join(data_path_fast,'wiki-news-300d-1M.vec')\n",
    "print(\"loading fasttext model...\")\n",
    "fasttext_model = KeyedVectors.load_word2vec_format(path_to_model_fasttext)\n",
    "print(\"done loading fasttext model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load spacy model\n",
    "nlp=spacy.load('en_core_web_lg')\n",
    "print(\"spacy model loaded....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load w2v model\n",
    "data_path_w2v= \"/home/srinivas/Downloads\"\n",
    "path_to_model = os.path.join(data_path_w2v,'GoogleNews-vectors-negative300.bin')\n",
    "print(\"loading...\")\n",
    "w2v_model = KeyedVectors.load_word2vec_format(path_to_model, binary=True)\n",
    "print(\"done loading...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    review = re.sub('[^a-zA-Z]', ' ',text )#replace everything excepts aphabets\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    \n",
    "    review = [word for word in review if not word in stopwords.words('english')]\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset Preprocessing(removing stop words and html tags and punctuations)\n",
    "def create_corpus():\n",
    "    corpus = []\n",
    "    for i in range(0, len(df)):\n",
    "        review = re.sub('[^a-zA-Z]', ' ', df[\"query\"][i])#replace everything excepts aphabets\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "\n",
    "        review = [word for word in review if not word in stopwords.words('english')]\n",
    "        corpus.append(review)\n",
    "    print(\"done\")\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpus_spacy():\n",
    "    corpus = []\n",
    "    for i in range(0, len(df)):\n",
    "        review = re.sub('[^a-zA-Z]', ' ', df[\"atom\"][i])#replace everything excepts aphabets\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "\n",
    "        review = [word for word in review if not word in stopwords.words('english')]\n",
    "        review=\" \".join(review)\n",
    "        corpus.append(review)\n",
    "    print(\"done\")\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedd_spacy():\n",
    "    corpus=create_corpus_spacy()\n",
    "    print(corpus)\n",
    "    feats=[]\n",
    "    for x in corpus:\n",
    "        features=nlp(x)\n",
    "        features=features.vector\n",
    "        if np.count_nonzero(features)==0:\n",
    "            return [np.ones(300)]\n",
    "        feats.append(features)\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedd_corpus_fasttext():\n",
    "    corpus=create_corpus()\n",
    "    print(corpus)\n",
    "    feats=[]\n",
    "    Dimension=300\n",
    "    for sentence in corpus:\n",
    "        feat_for_this=np.zeros(Dimension)\n",
    "        count=0\n",
    "        for word in sentence:\n",
    "            if word in fasttext_model:\n",
    "                feat_for_this += fasttext_model[word]\n",
    "                count+=1\n",
    "        if count==0:\n",
    "            count=1\n",
    "            print(\"yessss\")\n",
    "            feat_for_this=np.ones(Dimension)\n",
    "        feats.append(feat_for_this/count)\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedd_corpus_w2v():\n",
    "    corpus=create_corpus()\n",
    "    print(corpus)\n",
    "    feats=[]\n",
    "    Dimension=300\n",
    "    for sentence in corpus:\n",
    "        feat_for_this=np.zeros(Dimension)\n",
    "        count=0\n",
    "        for word in sentence:\n",
    "            if word in w2v_model:\n",
    "                feat_for_this += w2v_model[word]\n",
    "                count+=1\n",
    "        if count==0:\n",
    "            count=1\n",
    "            print(\"yessss\")\n",
    "            feat_for_this=np.ones(Dimension)\n",
    "        feats.append(feat_for_this/count)\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_spacy(que):\n",
    "    que=clean(que)\n",
    "    que=\" \".join(que)\n",
    "    print(que)\n",
    "    features=nlp(que)\n",
    "    features=features.vector\n",
    "    if np.count_nonzero(features)==0:\n",
    "        print(\"This is a UNIT VECTOR!!\")\n",
    "        return np.ones(300)\n",
    "    return features\n",
    "\n",
    "def single_w2v(que):\n",
    "    que=clean(que)\n",
    "    print(que)\n",
    "    Dimension=300\n",
    "    \n",
    "    feat_for_this=np.zeros(Dimension)\n",
    "    count=0\n",
    "    for word in que:\n",
    "        if word in w2v_model:\n",
    "            feat_for_this += w2v_model[word]\n",
    "            count+=1\n",
    "    if count==0:\n",
    "        print(\"This is a UNIT VECTOR!!\")\n",
    "        return np.ones(Dimension)\n",
    "    #print(count)\n",
    "    return (feat_for_this/count)\n",
    "\n",
    "def single_fasttext(que):\n",
    "    que=clean(que)\n",
    "    print(que)\n",
    "    Dimension=300\n",
    "    \n",
    "    feat_for_this=np.zeros(Dimension)\n",
    "    count=0\n",
    "    for word in que:\n",
    "        if word in fasttext_model:\n",
    "            #print(word)\n",
    "            feat_for_this += fasttext_model[word]\n",
    "            count+=1\n",
    "    if count==0:\n",
    "        print(\"This is a UNIT VECTOR!!\")\n",
    "        return np.ones(Dimension)\n",
    "    #print(count)\n",
    "    return (feat_for_this/count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_vec=embedd_corpus_fasttext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"atom\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/srinivas/Desktop/validation_arrays/fasttext_answer_.pkl','wb') as f:\n",
    "     pickle.dump(fast_vec, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/srinivas/Desktop/validation_arrays/fasttext_answer_.pkl','rb') as f:\n",
    "     x_answer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_vec_question=embedd_corpus_fasttext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"atom\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/srinivas/Desktop/validation_arrays/fasttext_question.pkl','wb') as f:\n",
    "     pickle.dump(fast_vec_question, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/srinivas/Desktop/validation_arrays/fasttext_question.pkl','rb') as f:\n",
    "     x_ques = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_ques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_vec_q=embedd_corpus_w2v()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_vec_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/srinivas/Desktop/validation_arrays/w2v_question.pkl','wb') as f:\n",
    "     pickle.dump(w2v_vec_question, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/srinivas/Desktop/validation_arrays/w2v_question.pkl','rb') as f:\n",
    "     w2v_ques = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_vec=embedd_spacy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_vec=bc.encode(list(df[\"atom\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bert_vec[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/srinivas/Desktop/validation_arrays/bert/bert_answer.pkl','wb') as f:\n",
    "     pickle.dump(bert_vec, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/srinivas/Desktop/validation_arrays/bert/bert_answer.pkl','rb') as f:\n",
    "     x77 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x77[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_a=list(df[\"atom\"])\n",
    "bert_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bert_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_vec_answer=bc.encode(bert_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bert_vec_answer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/srinivas/Desktop/validation_arrays/bert/bert_answer.pkl','wb') as f:\n",
    "     pickle.dump(bert_vec_answer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/srinivas/Desktop/validation_arrays/bert/bert_answer.pkl','rb') as f:\n",
    "     xa= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xa[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bert_vec_question[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"query\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(spacy_vec))\n",
    "print(len(fast_vec))\n",
    "print(len(w2v_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(spacy_vec[0]))\n",
    "print(len(fast_vec[0]))\n",
    "print(len(w2v_vec[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fasttext\"]=fast_vec\n",
    "df[\"w2v\"]=w2v_vec\n",
    "df[\"spacy\"]=spacy_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"./validation_data_with_3_w2v_vectors.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings = {\n",
    "   \"settings\":{\n",
    "      \"number_of_shards\":1,\n",
    "      \"number_of_replicas\":0\n",
    "   },\n",
    "   \"mappings\":{\n",
    "       \"dynamic\": \"true\",\n",
    "        \"_source\": {\n",
    "        \"enabled\": \"true\"\n",
    "        },\n",
    "       \"properties\":{\n",
    "            \"answer\": {\n",
    "            \"type\": \"text\"\n",
    "            },\n",
    "          \"fasttext_vector\":{\n",
    "         \"type\":\"dense_vector\",\n",
    "         \"dims\":300\n",
    "      },\n",
    "        \"w2v_vector\":{\n",
    "         \"type\":\"dense_vector\",\n",
    "         \"dims\":300\n",
    "      },\n",
    "        \"spacy_vector\":{\n",
    "         \"type\":\"dense_vector\",\n",
    "         \"dims\":300\n",
    "      },\n",
    "          \"country\":{  \n",
    "            \"type\":\"text\"\n",
    "         },   \n",
    "          \"product\":{  \n",
    "            \"type\":\"text\"\n",
    "         }\n",
    "    }\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT = \"http://localhost:9200/\"\n",
    "es = Elasticsearch(timeout=600,hosts=ENDPOINT)\n",
    "print(\"python client created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the database\n",
    "IndexName = 'ensemble_w2v_models'\n",
    "my = es.indices.create(index=IndexName, ignore=[400,404], body=Settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df22 = df.to_dict('records')\n",
    "df22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=[]\n",
    "for c, line in enumerate(df22):\n",
    "    arr.append({\"answer\":line.get(\"atom\",\"\"),\n",
    "    'fasttext_vector':line.get(\"fasttext\",\"\"),\n",
    "    'w2v_vector':line.get(\"w2v\",\"\"),\n",
    "    'spacy_vector':line.get(\"spacy\",\"\"),\n",
    "    'country':line.get(\"country\",\"\").lower().strip(),\n",
    "    'product':line.get(\"product\",\"\").lower().strip()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(arr)):\n",
    "\n",
    "    resp=es.index(index=IndexName,doc_type=\"_doc\",id=i,body=arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "que=\"what is Crestor used for in canada?\"\n",
    "print(que)\n",
    "temp_prod=df[\"product\"]\n",
    "temp_country=df[\"country\"]\n",
    "product_list=list(set(temp_prod))\n",
    "print(product_list)\n",
    "country_list=list(set(temp_country))\n",
    "print(country_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_1=single_w2v(que)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_generator():    \n",
    "    temp_prod=df[\"product\"]\n",
    "    temp_country=df[\"country\"]\n",
    "\n",
    "    product_list=list(set(temp_prod))\n",
    "    country_list=list(set(temp_country))\n",
    "\n",
    "    for i in range(0,len(product_list)):\n",
    "        product_list[i]=product_list[i].lower()\n",
    "\n",
    "    for i in range(0,len(country_list)):\n",
    "        country_list[i]=country_list[i].lower().strip()\n",
    "\n",
    "    prods=[]\n",
    "\n",
    "    for x in product_list:\n",
    "        temp=x.split(\"(\")\n",
    "        for i in range(0,len(temp)):\n",
    "            temp[i]=temp[i].replace(\")\",\"\")\n",
    "            temp[i]=temp[i].strip()\n",
    "            prods.append(temp[i])\n",
    "    return [prods,country_list]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_creator(que,lists):    \n",
    "    prods=lists[0]\n",
    "    country_list=lists[1]\n",
    "    print(prods)\n",
    "    print(country_list)\n",
    "    \n",
    "    spacy_vec=single_spacy(que)\n",
    "    w2v_vec=single_w2v(que)\n",
    "    fasttext_vec=single_fasttext(que)\n",
    "    #print(que_vec)\n",
    "    #print(que)\n",
    "    que=que.lower()\n",
    "    p=\"\"\n",
    "    c=\"\"\n",
    "    for x in prods:\n",
    "        if x in que:\n",
    "            p=x\n",
    "            print(p)\n",
    "            break\n",
    "    for x in country_list:\n",
    "        if x in que:\n",
    "            c=x\n",
    "            print(c)\n",
    "\n",
    "    script_query={}\n",
    "    if p!=\"\" and c!=\"\":\n",
    "        print(\"1...........\")\n",
    "        script_query = {\n",
    "        \"script_score\": {\n",
    "        \"query\": {\n",
    "    \"bool\": {\n",
    "      \"must\": [\n",
    "        {\n",
    "          \"match\": {\n",
    "            \"product\": p\n",
    "          }\n",
    "        }\n",
    "      ],\n",
    "      \"should\": [\n",
    "        {\n",
    "          \"match\": {\n",
    "            \"country\": c\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  },\n",
    "        \"script\": {\n",
    "        \"source\": \"((Math.abs(cosineSimilarity(params.spacy_vector, doc['spacy_vector'])))+(Math.abs(cosineSimilarity(params.w2v_vector, doc['w2v_vector'])))+(Math.abs(cosineSimilarity(params.fasttext_vector, doc['fasttext_vector']))))/3\",\n",
    "        \"params\": {\"spacy_vector\": spacy_vec,\"w2v_vector\": w2v_vec,\"fasttext_vector\": fasttext_vec}\n",
    "        }}}\n",
    "\n",
    "    elif p!=\"\" and c==\"\":\n",
    "        print(\"2...........\")\n",
    "        script_query = {\n",
    "        \"script_score\": {\n",
    "        \"query\": {\"match\": {\n",
    "              \"product\": {\n",
    "                \"query\":p\n",
    "              }}},\n",
    "        \"script\": {\n",
    "        \"source\": \"((Math.abs(cosineSimilarity(params.spacy_vector, doc['spacy_vector'])))+(Math.abs(cosineSimilarity(params.w2v_vector, doc['w2v_vector'])))+(Math.abs(cosineSimilarity(params.fasttext_vector, doc['fasttext_vector']))))/3\",\n",
    "        \"params\": {\"spacy_vector\": spacy_vec,\"w2v_vector\": w2v_vec,\"fasttext_vector\": fasttext_vec}\n",
    "        }}}\n",
    "    elif p==\"\" and c!=\"\":\n",
    "        print(\"3...........\")\n",
    "        script_query = {\n",
    "        \"script_score\": {\n",
    "        \"query\": {\"match\": {\n",
    "              \"country\": {\n",
    "                \"query\":c\n",
    "              }}},\n",
    "        \"script\": {\n",
    "        \"source\": \"((Math.abs(cosineSimilarity(params.spacy_vector, doc['spacy_vector'])))+(Math.abs(cosineSimilarity(params.w2v_vector, doc['w2v_vector'])))+(Math.abs(cosineSimilarity(params.fasttext_vector, doc['fasttext_vector']))))/3\",\n",
    "        \"params\": {\"spacy_vector\": spacy_vec,\"w2v_vector\": w2v_vec,\"fasttext_vector\": fasttext_vec}\n",
    "        }}}\n",
    "    else:\n",
    "        print(\"4...........\")\n",
    "        script_query = {\n",
    "        \"script_score\": {\n",
    "        \"query\": {\"match_all\": {}},\n",
    "        \"script\": {\n",
    "        \"source\": \"((Math.abs(cosineSimilarity(params.spacy_vector, doc['spacy_vector'])))+(Math.abs(cosineSimilarity(params.w2v_vector, doc['w2v_vector'])))+(Math.abs(cosineSimilarity(params.fasttext_vector, doc['fasttext_vector']))))/3\",\n",
    "        \"params\": {\"spacy_vector\": spacy_vec,\"w2v_vector\": w2v_vec,\"fasttext_vector\": fasttext_vec}\n",
    "        }}}\n",
    "    return  script_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists=list_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "que=\"what is Crestor used for ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_query=query_creator(que,lists)\n",
    "script_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=es.search(index=IndexName,body={\"size\": 10,\"query\": script_query,\"_source\": {\"includes\": [\"answer\",\"country\",\"product\"]}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def questions():\n",
    "    count=0\n",
    "    que_arr=[]\n",
    "    for x in df[\"query\"]:\n",
    "        sent=x.split(\"\\n\")\n",
    "        for q in sent:\n",
    "            if re.search('[a-zA-Z]',q)!=None:\n",
    "                que_arr.append([q,count])\n",
    "        count+=1\n",
    "    return que_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "que_arr=questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(que_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "que_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rank(ans):\n",
    "    required=ans['hits']\n",
    "    main_arr=required[\"hits\"]\n",
    "    count=1\n",
    "    ids__=dict()\n",
    "    for x in main_arr:\n",
    "        id_no= x[\"_id\"]\n",
    "\n",
    "        score=x[\"_score\"]\n",
    "\n",
    "        answer_=x[\"_source\"][\"answer\"]\n",
    "        \n",
    "        ids__[id_no.strip()]=1/count\n",
    "        count+=1\n",
    "    return ids__\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker=rank(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=es.search(index=IndexName,body={\"size\": 10,\"query\": script_query,\"_source\": {\"includes\": [\"answer\"]}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr():\n",
    "    total=0\n",
    "    count=0\n",
    "    recall_count=0\n",
    "    lists_all=list_generator()\n",
    "    print(lists_all)\n",
    "    for x in que_arr:\n",
    "        question_=x[0].strip()\n",
    "        print(question_)\n",
    "        id_number=str(x[1])\n",
    "\n",
    "        script_query_curr=query_creator(question_,lists_all)\n",
    "        ans=es.search(index=IndexName,body={\"size\": 10,\"query\": script_query_curr,\"_source\": {\"includes\": [\"answer\",\"product\",\"country\"]}})\n",
    "        ranker=rank(ans)\n",
    "        if id_number in ranker:\n",
    "            total+=ranker[id_number]\n",
    "            print(ranker[id_number])\n",
    "            recall_count+=1\n",
    "        else:\n",
    "            print(0)\n",
    "        count+=1\n",
    "\n",
    "    print(\"mrr is\"+str(total/count))\n",
    "    print(\"recall is\"+str(recall_count/count))\n",
    "    return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biobert",
   "language": "python",
   "name": "success"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
